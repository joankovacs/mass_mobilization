{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial imports and declarations\n",
    "Will be expanded later to include a bevy of imports for various processing, data exploration, and modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "\n",
    "#models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#post-modelling metrics\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"protests.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Structures \n",
    "Includes function declarations, lists, dictionaries, etc. that are used later in the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Response and demands were dummified due to how the data was entered.  The dummies were then combined into a single response or demand column that had a binary value.\n",
    "response_drops = [\n",
    "    '1_accomodation', '1_arrests', '1_beatings', '1_crowd dispersal', '1_ignore', '1_killings', '1_shootings',\n",
    "    '2_accomodation', '2_arrests', '2_beatings', '2_crowd dispersal', '2_ignore', '2_killings', '2_shootings', \n",
    "    '3_accomodation', '3_arrests', '3_beatings', '3_crowd dispersal', '3_ignore', '3_killings', '3_shootings', \n",
    "    '4_accomodation', '4_arrests', '4_beatings', '4_crowd dispersal', '4_killings', '4_shootings', \n",
    "    '5_.', '5_accomodation', '5_arrests', '5_beatings', '5_crowd dispersal', '5_killings', '5_shootings', \n",
    "    '6_accomodation', '6_arrests', '6_beatings', '6_crowd dispersal', '6_killings', \n",
    "    '7_.', '7_accomodation', '7_arrests', '7_beatings', '7_killings'\n",
    "]\n",
    "\n",
    "demand_drops = [\n",
    "    'demand1_labor wage dispute', 'demand1_land farm issue', 'demand1_police brutality', 'demand1_political behavior, process', 'demand1_price increases, tax policy', 'demand1_removal of politician', 'demand1_social restrictions', \n",
    "    'demand2_labor wage dispute', 'demand2_land farm issue', 'demand2_police brutality', 'demand2_political behavior, process', 'demand2_price increases, tax policy', 'demand2_removal of politician', 'demand2_social restrictions', \n",
    "    'demand3_labor wage dispute', 'demand3_land farm issue', 'demand3_police brutality', 'demand3_political behavior, process', 'demand3_price increases, tax policy', 'demand3_removal of politician', 'demand3_social restrictions', \n",
    "    'demand4_.', 'demand4_labor wage dispute', 'demand4_land farm issue', 'demand4_police brutality', 'demand4_political behavior, process', 'demand4_price increases, tax policy', 'demand4_removal of politician'\n",
    "]\n",
    "\n",
    "#After the length of the protest in days was determined, the particulars about when it started or ended were dropped.  \n",
    "#The year of occurence was maintained in another column.\n",
    "time_drops = ['startday', 'startmonth', 'startyear', 'endday', 'endmonth', 'endyear']\n",
    "\n",
    "other_drops = [\n",
    "    'id', #Not useful to prediction.\n",
    "    'ccode', #Not useful to prediction.\n",
    "    'protest', #All values are 1.  Is this dataset the subset of another?\n",
    "    'protestnumber', # of protests per country might be useful but not in the context of incremental numbers that it's being given\n",
    "    'location', #Not extremely useable given how it's already being broken by region.\n",
    "    'participants_category', #Too many null values to be of great value.\n",
    "]\n",
    "\n",
    "#Demands & response are the aggregated columns for their respective types\n",
    "demands = ['protesterdemand1', 'protesterdemand2', 'protesterdemand3', 'protesterdemand4']\n",
    "\n",
    "response = [\"stateresponse1\", \"stateresponse2\", \"stateresponse3\", \"stateresponse4\", \"stateresponse5\", \"stateresponse6\", \"stateresponse7\"]\n",
    "\n",
    "#These will be the new engineered target columns for state responses, on a binary value.\n",
    "targets = ['y_accomodation', 'y_arrests', 'y_beatings', 'y_crowd dispersal', 'y_ignore', 'y_killings', 'y_shootings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These four functions are text analysis for the Participants feature so that it can be converted to numeric.  \n",
    "#This covered around 99% of cases in the dataframe.\n",
    "#First, the text parser immediately converts a number to numeric if the string matches expectations.\n",
    "#Second, strip_chars tries to parse numeric input that has special characters in it.  It attempts to convert it to an integer but if that fails then it passes back a string.\n",
    "#Third, if a number is hyphenated (\"100-1000\") then it parses those as two separate numbers and averages them.\n",
    "#Finally, if it does all of the above and the entry can't be converted to numeric, it's converted to NaN and dropped.\n",
    "\n",
    "\n",
    "def parse_texts(x):\n",
    "    x = x.lower()\n",
    "    \n",
    "    if x == \"dozens\":\n",
    "        return 50\n",
    "    elif x == \"hundreds\":\n",
    "        return 500\n",
    "    elif x == \"thousands\":\n",
    "        return 5000\n",
    "    elif x == \"tens of thousands\":\n",
    "        return 50000\n",
    "    elif \"hundreds of thousands\" in x:\n",
    "        return 250000\n",
    "    elif \"millions\" in x:\n",
    "        return 2000000\n",
    "    elif \"million\" in x:\n",
    "        return 1000000\n",
    "    \n",
    "    \n",
    "    elif \"about \" in x:\n",
    "        return x[6:]\n",
    "    elif \"more than \" in x:\n",
    "        return x[10:]\n",
    "    \n",
    "    \n",
    "    elif \"several\" in x:\n",
    "        if \"dozen\" in x:\n",
    "            return 50\n",
    "        elif \"hundred\" in x:\n",
    "            return 500\n",
    "        elif \"thousand\" in x:\n",
    "            return 5000\n",
    "    \n",
    "    \n",
    "    elif \"hundreds\" in x:\n",
    "        return 500\n",
    "    elif \"thousands\" in x:\n",
    "        return 5000\n",
    "    \n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def strip_chars(x):\n",
    "    banned_chars = \"+s><,\"\n",
    "    x = \"\".join([c for c in x if c not in banned_chars])\n",
    "    \n",
    "    try:\n",
    "        x = int(x)\n",
    "    finally:\n",
    "        return x\n",
    "\n",
    "\n",
    "    \n",
    "def avg_hyphen(x):\n",
    "    accepted_chars = \"1234567890-\"\n",
    "    ind = 0\n",
    "\n",
    "    x = \"\".join([c for c in x if c in accepted_chars])\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        if x[i] == \"-\":\n",
    "            ind = i\n",
    "    \n",
    "    lower = x[:ind]\n",
    "    upper = x[ind+1:]\n",
    "    \n",
    "    if (lower == \"\") or (upper==\"\"):\n",
    "        return np.nan\n",
    "    \n",
    "    return (int(lower) + int(upper)) /2\n",
    "    \n",
    "    \n",
    "    \n",
    "def map_participants(x):\n",
    "    while type(x) == str:\n",
    "        x = parse_texts(x)\n",
    "        if type(x) == str:\n",
    "            x = strip_chars(x)\n",
    "        if type(x) == str:\n",
    "            x = avg_hyphen(x)\n",
    "        if type(x) == str:\n",
    "            x = np.nan\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Cleaning\n",
    "Contains blocks of code for known cleaning problems derived from any previous data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General/Miscellaneous Cleaning\n",
    "\n",
    "df.dropna(subset=[\"notes\"], inplace=True) #If there are no notes, then we will not be able to predict the outcome very well.\n",
    "df.dropna(subset=[\"participants\"], inplace=True) #Participants had very few NaN values\n",
    "df.dropna(subset=[\"sources\"], inplace=True) #Sources had very few NaN values\n",
    "\n",
    "\n",
    "#Miscellaneous useless feature cleaning.  See the list declaration [other_drops] in DATA STRUCTURES for additional information.\n",
    "df.drop(columns=other_drops, inplace=True)\n",
    "\n",
    "\n",
    "#For the 500 or so values containing NaN in protestor identity:\n",
    "df.fillna(value={\"protesteridentity\":\"unspecified\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arcosion/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#For fixing the time values such that a length of time (in days) for the protest is established as a feature, and other time features are dropped.\n",
    "#Critically, the year the protest initially occured is retained in another column.\n",
    "\n",
    "month_days = {1:0, 2:31, 3:59, 4:90, 5:120, 6:151, 7:181, 8:212, 9:243, 10:273, 11:304, 12:334}\n",
    "df[\"protest_length\"] = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    yearday_start = month_days[df[\"startmonth\"].iloc[i]] + df[\"startday\"].iloc[i]\n",
    "    yearday_end = month_days[df[\"endmonth\"].iloc[i]] + df[\"endday\"].iloc[i]\n",
    "    \n",
    "    difference = (yearday_end - yearday_start) + (365 * (df[\"endyear\"].iloc[i] - df[\"startyear\"].iloc[i]))\n",
    "    \n",
    "    if difference != 0:\n",
    "        df[\"protest_length\"].iloc[i] = difference\n",
    "    else:\n",
    "        df[\"protest_length\"].iloc[i] = 1 #accounts for same-day protests\n",
    "\n",
    "\n",
    "#Now that the length is obtained, the additional time columns can be dropped.\n",
    "df.drop(columns=time_drops, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For fixing the Participants feature such that we have a numerical value.\n",
    "#For more information, see the function map_participants() in DATA STRUCTURES.\n",
    "df[\"participants\"] = df[\"participants\"].map(map_participants)\n",
    "\n",
    "df.dropna(subset=[\"participants\"], inplace=True) #150 null values remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For translating the vertical state response & the protester demands values laterally.\n",
    "\n",
    "\n",
    "df = pd.get_dummies(data=df, prefix=[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], columns=response)\n",
    "df = pd.get_dummies(data=df, prefix=[\"demand1\", \"demand2\", \"demand3\", \"demand4\"], columns=demands)\n",
    "\n",
    "\n",
    "#Combining the disparate dummies into unified response columns.  \n",
    "#Unfortunately there was a certain amount of manual labor involved in this due to how finicky pandas is.\n",
    "df[\"demand_labor_wage_dispute\"] = df['demand1_labor wage dispute'] + df['demand2_labor wage dispute'] + df['demand3_labor wage dispute'] + df['demand4_labor wage dispute']\n",
    "df[\"demand_land_farm_issue\"] = df['demand1_land farm issue'] + df['demand2_land farm issue'] + df['demand3_land farm issue'] + df['demand4_land farm issue']\n",
    "df[\"demand_police_brutality\"] = df['demand1_police brutality'] + df['demand2_police brutality'] + df['demand3_police brutality'] + df['demand4_police brutality']\n",
    "df[\"demand_political_behavior_or_process\"] = df['demand1_political behavior, process'] + df['demand2_political behavior, process'] + df['demand3_political behavior, process'] + df['demand4_political behavior, process']\n",
    "df[\"demand_price_hike_or_tax_policy\"] = df['demand1_price increases, tax policy'] + df['demand2_price increases, tax policy'] + df['demand3_price increases, tax policy'] + df['demand4_price increases, tax policy']\n",
    "df[\"demand_removal_of_politician\"] = df['demand1_removal of politician'] + df['demand2_removal of politician'] + df['demand3_removal of politician'] + df['demand4_removal of politician']\n",
    "df[\"demand_social_restrictions\"] = df['demand1_social restrictions'] + df['demand2_social restrictions'] + df['demand3_social restrictions']\n",
    "\n",
    "df[\"y_accomodation\"] = df['1_accomodation'] + df['2_accomodation'] + df['3_accomodation'] + df['4_accomodation'] + df['5_accomodation'] + df['6_accomodation'] + df['7_accomodation']\n",
    "df[\"y_arrests\"] = df['1_arrests'] + df['2_arrests'] + df['3_arrests'] + df['4_arrests'] + df['5_arrests'] + df['6_arrests'] + df['7_arrests']\n",
    "df[\"y_beatings\"] = df['1_beatings'] + df['2_beatings'] + df['3_beatings'] + df['4_beatings'] + df['5_beatings'] + df['6_beatings'] + df['7_beatings']\n",
    "df[\"y_crowd_dispersal\"] = df['1_crowd dispersal'] + df['2_crowd dispersal'] + df['3_crowd dispersal'] + df['4_crowd dispersal'] + df['5_crowd dispersal'] + df['6_crowd dispersal']\n",
    "df[\"y_ignore\"] = df['1_ignore'] + df['2_ignore'] + df['3_ignore']\n",
    "df[\"y_killings\"] = df['1_killings'] + df['2_killings'] + df['3_killings'] + df['4_killings'] + df['5_killings'] + df['6_killings'] + df['7_killings']\n",
    "df[\"y_shootings\"] = df['1_shootings'] + df['2_shootings'] + df['3_shootings'] + df['4_shootings'] + df['5_shootings']\n",
    "\n",
    "\n",
    "\n",
    "#Getting rid of the disparate dummies now that we have unified responses.\n",
    "df.drop(columns=response_drops, inplace=True)\n",
    "df.drop(columns=demand_drops, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, dropping Oceania due to the limited number of entries for that region.\n",
    "df = df[df[\"region\"] != \"Oceania\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data exploration & analysis\n",
    "This dataframe was primarily used for modelling; therefore, this section in this dataframe was used mostly for activities like fetching columns names and the like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14264 entries, 0 to 16312\n",
      "Data columns (total 23 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   country                               14264 non-null  object \n",
      " 1   year                                  14264 non-null  int64  \n",
      " 2   region                                14264 non-null  object \n",
      " 3   protesterviolence                     14264 non-null  float64\n",
      " 4   participants                          14264 non-null  float64\n",
      " 5   protesteridentity                     14264 non-null  object \n",
      " 6   sources                               14264 non-null  object \n",
      " 7   notes                                 14264 non-null  object \n",
      " 8   protest_length                        14264 non-null  float64\n",
      " 9   demand_labor_wage_dispute             14264 non-null  uint8  \n",
      " 10  demand_land_farm_issue                14264 non-null  uint8  \n",
      " 11  demand_police_brutality               14264 non-null  uint8  \n",
      " 12  demand_political_behavior_or_process  14264 non-null  uint8  \n",
      " 13  demand_price_hike_or_tax_policy       14264 non-null  uint8  \n",
      " 14  demand_removal_of_politician          14264 non-null  uint8  \n",
      " 15  demand_social_restrictions            14264 non-null  uint8  \n",
      " 16  y_accomodation                        14264 non-null  uint8  \n",
      " 17  y_arrests                             14264 non-null  uint8  \n",
      " 18  y_beatings                            14264 non-null  uint8  \n",
      " 19  y_crowd_dispersal                     14264 non-null  uint8  \n",
      " 20  y_ignore                              14264 non-null  uint8  \n",
      " 21  y_killings                            14264 non-null  uint8  \n",
      " 22  y_shootings                           14264 non-null  uint8  \n",
      "dtypes: float64(3), int64(1), object(5), uint8(14)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Modelling\n",
    "\n",
    "---\n",
    " An overview of the methodology below: \n",
    "Four models were gridsearched to try and find the best-working model for the disparate data.  Significant care was taken to construct appropriate functions and loops for the task at hand that were side effect free.  The four core gridsearch functions each return a dictionary that can be appended to a results dataframe, which was then analyzed for success.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique values for regions and countries were fetched.  Features were gathered for use in the models.\n",
    "possible_responses = ['y_accomodation', 'y_arrests', 'y_beatings', 'y_crowd_dispersal', 'y_ignore', 'y_killings', 'y_shootings']\n",
    "\n",
    "region_list = dict(df[\"region\"].value_counts()).keys()\n",
    "\n",
    "country_list = dict(df[\"country\"].value_counts()).keys()\n",
    "\n",
    "all_features = ['year', 'protesterviolence', 'participants', 'protest_length',\n",
    "       'demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
    "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
    "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
    "       'demand_social_restrictions', 'notes']\n",
    "\n",
    "num_features = ['year', 'protesterviolence', 'participants', 'protest_length',\n",
    "       'demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
    "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
    "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
    "       'demand_social_restrictions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Some common notes on the four gridsearch functions:  FeatureUnion was used to unify both text and numeric data into a single outcome.  Each pipeline fed into the gridsearch contains a FeatureUnion, which contains two pipelines - one for numeric data & one for text data, which are preprocessed with StandardScaler and CountVectorizer respectively.  The outermost pipeline then passes the results of the first entry (FeatureUnion) into the model in question.  FunctionTransformers fetch the appropriate data for each interior pipeline.\n",
    "\n",
    "The process was extremely computationally expensive because in addition to whatever gridsearch parameters we were running, we had a \"built in\" model multiplier of 49 - 7 responses and 7 regions.  Therefore, we didn't do as much gridsearching as we wanted.\n",
    "\n",
    "Finally, the results of each model run for a given region and a given response is passed into a dictionary which is then returned.  A for loop running through all of these models appends the results to a dataframe.\n",
    "___\n",
    "---\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg__protest_by_the_response(df, response):    \n",
    "    X = df[all_features]\n",
    "    y = df[response]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    \n",
    "    get_numeric_data = FunctionTransformer(lambda df: df[num_features], validate=False)\n",
    "    get_text_data = FunctionTransformer(lambda df: df['notes'], validate=False)\n",
    "    \n",
    "    \n",
    "    pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "             ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer(stop_words='english'))\n",
    "            ]))\n",
    "         ])),\n",
    "    ('log', LogisticRegression(max_iter=5000))\n",
    "    ])\n",
    "    \n",
    "    params = {\n",
    "        'log__penalty' : ['l2', 'l1'],\n",
    "#        'log__C' : [0.001, 0.01, 0,1, 1, 5],\n",
    "#        'features__text_features__cvec__max_df': [0.90, 0.95],\n",
    "#        'features__text_features__cvec__max_features': [None, 1000, 3000, 5000],\n",
    "        'log__solver' : ['liblinear']\n",
    "    }\n",
    "    \n",
    "\n",
    "    gs = GridSearchCV(pipe, param_grid=params, cv=5, verbose=0)\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Grab the baseline for comparison\n",
    "    baseline = max([df[response].mean(), 1-df[response].mean()])\n",
    "    \n",
    "    #declare the dictionary which is returned and then appended as a row in a results dataframe\n",
    "    reg_response_dict = {\n",
    "        \"model_type\": \"logreg\",\n",
    "        \"region\": df[\"region\"].iloc[0],\n",
    "        \"training_score\": gs.score(X_train, y_train),\n",
    "        \"testing_score\": gs.score(X_test, y_test),\n",
    "        \"baseline\": baseline,\n",
    "        \"baseline_response\": (response[2:] if df[response].mean() > 0.5 else f\"no {response[2:]}\"),\n",
    "        \"model_success\": (\"yes\" if gs.score(X_test, y_test) > (0.05+baseline) else \"no\"),\n",
    "        \"best_params\": gs.best_params_\n",
    "    }\n",
    "    \n",
    "    return reg_response_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf__protest_by_the_response(df, response):\n",
    "    X = df[all_features]\n",
    "    y = df[response]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    \n",
    "    get_numeric_data = FunctionTransformer(lambda df: df[num_features], validate=False)\n",
    "    get_text_data = FunctionTransformer(lambda df: df['notes'], validate=False)\n",
    "    \n",
    "    \n",
    "    pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "             ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer(stop_words='english'))\n",
    "            ]))\n",
    "         ])),\n",
    "    ('rf', RandomForestClassifier())\n",
    "    ])\n",
    "    \n",
    "    params = {\n",
    "#        'rf__ccp_alpha' : [0.001, 0.01, 0.1, 1, 5],\n",
    "        'rf__n_estimators' : [100, 300],\n",
    "        'rf__max_depth' : [None, 5, 10],\n",
    "        'rf__min_samples_split' : [2, 4],\n",
    "        'rf__min_samples_leaf' : [1, 3]\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(pipe, param_grid=params, cv=5, verbose=0)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    baseline = max([df[response].mean(), 1-df[response].mean()])\n",
    "            \n",
    "    reg_response_dict = {\n",
    "        \"model_type\": \"rf\",\n",
    "        \"region\": df[\"region\"].iloc[0],\n",
    "        \"training_score\": gs.score(X_train, y_train),\n",
    "        \"testing_score\": gs.score(X_test, y_test),\n",
    "        \"baseline\": baseline,\n",
    "        \"baseline_response\": (response[2:] if df[response].mean() > 0.5 else f\"no {response[2:]}\"),\n",
    "        \"model_success\": (\"yes\" if gs.score(X_test, y_test) > (0.05+baseline) else \"no\"),\n",
    "        \"best_params\": gs.best_params_\n",
    "    }\n",
    "    \n",
    "    return reg_response_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc__protest_by_the_response(df, response):\n",
    "    X = df[all_features]\n",
    "    y = df[response]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    \n",
    "    get_numeric_data = FunctionTransformer(lambda df: df[num_features], validate=False)\n",
    "    get_text_data = FunctionTransformer(lambda df: df['notes'], validate=False)\n",
    "    \n",
    "    \n",
    "    pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "             ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer(stop_words='english'))\n",
    "            ]))\n",
    "         ])),\n",
    "    ('svc', SVC())\n",
    "    ])\n",
    "    \n",
    "    params = {\n",
    "        'svc__C' : [5],\n",
    "        'svc__degree' :[2],\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(pipe, param_grid=params, cv=5, verbose=0)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    baseline = max([df[response].mean(), 1-df[response].mean()])\n",
    "            \n",
    "    reg_response_dict = {\n",
    "        \"model_type\": \"svc\",\n",
    "        \"region\": df[\"region\"].iloc[0],\n",
    "        \"training_score\": gs.score(X_train, y_train),\n",
    "        \"testing_score\": gs.score(X_test, y_test),\n",
    "        \"baseline\": baseline,\n",
    "        \"baseline_response\": (response[2:] if df[response].mean() > 0.5 else f\"no {response[2:]}\"),\n",
    "        \"model_success\": (\"yes\" if gs.score(X_test, y_test) > (0.05+baseline) else \"no\"),\n",
    "        \"best_params\": gs.best_params_\n",
    "    }\n",
    "    \n",
    "    return reg_response_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb__protest_by_the_response(df, response):\n",
    "    X = df[all_features]\n",
    "    y = df[response]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    \n",
    "    get_numeric_data = FunctionTransformer(lambda df: df[num_features], validate=False)\n",
    "    get_text_data = FunctionTransformer(lambda df: df['notes'], validate=False)\n",
    "    \n",
    "    \n",
    "    pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "             ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer(stop_words='english'))\n",
    "            ]))\n",
    "         ])),\n",
    "    ('xg', XGBClassifier())\n",
    "    ])\n",
    "    \n",
    "    params = {\n",
    "#        'xg__gamma' : [0.001, 0.01, 0.1, 1, 5],\n",
    "        'xg__max_depth' :[None, 2, 3],\n",
    "#        'xg__learning_rate' : [0.001, 0.01, 0.1, 1, 5]\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(pipe, param_grid=params, cv=5, verbose=0)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    baseline = max([df[response].mean(), 1-df[response].mean()])\n",
    "            \n",
    "    reg_response_dict = {\n",
    "        \"model_type\": \"xgb\",\n",
    "        \"region\": df[\"region\"].iloc[0],\n",
    "        \"training_score\": gs.score(X_train, y_train),\n",
    "        \"testing_score\": gs.score(X_test, y_test),\n",
    "        \"baseline\": baseline,\n",
    "        \"baseline_response\": (response[2:] if df[response].mean() > 0.5 else f\"no {response[2:]}\"),\n",
    "        \"model_success\": (\"yes\" if gs.score(X_test, y_test) > (0.05+baseline) else \"no\"),\n",
    "        \"best_params\": gs.best_params_\n",
    "    }\n",
    "    \n",
    "    return reg_response_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Remaining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare an empty dataframe for the results to be appended into.\n",
    "grid_results = pd.DataFrame(columns=[\"model_type\", \"region\", \"baseline_response\", \"training_score\", \"testing_score\", \"baseline\", \"model_success\", \"best_params\"])\n",
    "\n",
    "\n",
    "#These four models correspond to each of the four model gridsearches.  It calls its corresponding model gridsearch function using a slice of the dataframe\n",
    "#divided by the continental \"regions\".  It returns a list of 7 dictionaries - one for each of the seven possible state responses.\n",
    "def logreg__responses_by_location(loc_df):\n",
    "    return [logreg__protest_by_the_response(loc_df, response) for response in possible_responses]\n",
    "\n",
    "def rf__responses_by_location(loc_df):\n",
    "    return [rf__protest_by_the_response(loc_df, response) for response in possible_responses]\n",
    "\n",
    "def svc__responses_by_location(loc_df):\n",
    "    return [svc__protest_by_the_response(loc_df, response) for response in possible_responses]\n",
    "\n",
    "def xgb__responses_by_location(loc_df):\n",
    "    return [xgb__protest_by_the_response(loc_df, response) for response in possible_responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This just returns a slice by the region of the dataframe overall.  Country ended up not being used.\n",
    "def df_by_region(df, region):\n",
    "    return df[df[\"region\"]==region]\n",
    "\n",
    "def df_by_country(df, country):\n",
    "    return df[df[\"country\"]==country]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Running the models\n",
    "---\n",
    "---\n",
    "For each of the 4 different gridsearch functions, a for-loop was run to get the results for each region. These for loops call the previous declared functions and append the returned dictionaries to the results dataframe.  In this way, we were able to troubleshoot each of the above functions without side effects - no restarting the kernel or messing up the dataframes already existing.  \n",
    "\n",
    "Credit goes to Kovacs' wife, Samantha Baldwin, for some help with the Python aspects of creating the function structure for running the models side-effect free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in region_list:\n",
    "    for dct in logreg__responses_by_location(df_by_region(df, region)):\n",
    "        grid_results = grid_results.append(dct, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in region_list:\n",
    "    for dct in rf__responses_by_location(df_by_region(df, region)):\n",
    "        grid_results = grid_results.append(dct, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in region_list:\n",
    "    for dct in svc__responses_by_location(df_by_region(df, region)):\n",
    "        grid_results = grid_results.append(dct, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in region_list:\n",
    "    for dct in xgb__responses_by_location(df_by_region(df, region)):\n",
    "        grid_results = grid_results.append(dct, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>region</th>\n",
       "      <th>baseline_response</th>\n",
       "      <th>training_score</th>\n",
       "      <th>testing_score</th>\n",
       "      <th>baseline</th>\n",
       "      <th>model_success</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model_type, region, baseline_response, training_score, testing_score, baseline, model_success, best_params]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The grid results were then appended to a dataframe.  This notebook does not have the results of the cells output for the above gridsearches\n",
    "#since the kernel was restarted at some point and these cells were too computationally expensive to re-run, but the results have all been preserved.\n",
    "grid_results.to_csv(\"./data/four_models.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Engineering & Assessment\n",
    "---\n",
    "---\n",
    "The four_models grid results were then analyzed to see which one worked best for additional fine-tuning.  The broader structure that has already been written was primarily a preliminary examination of the best working models since we didn't know what the results of using FeatureUnion would be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results = pd.read_csv(\"./data/four_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results[\"success_rate\"] = grid_results[\"testing_score\"] - grid_results[\"baseline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = grid_results[grid_results[\"model_type\"] == \"logreg\"][\"success_rate\"].mean()\n",
    "rf = grid_results[grid_results[\"model_type\"] == \"rf\"][\"success_rate\"].mean()\n",
    "svc = grid_results[grid_results[\"model_type\"] == \"svc\"][\"success_rate\"].mean()\n",
    "xgb = grid_results[grid_results[\"model_type\"] == \"xgb\"][\"success_rate\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\t0.04725500054879036\n",
      "Random Forest:\t\t0.051944471366851\n",
      "SVC:\t\t\t0.052335643254225385\n",
      "XGB Classifier:\t\t0.055978706244852044\n"
     ]
    }
   ],
   "source": [
    "print(f\"Logistic Regression:\\t{lg}\")\n",
    "print(f\"Random Forest:\\t\\t{rf}\")\n",
    "print(f\"SVC:\\t\\t\\t{svc}\")\n",
    "print(f\"XGB Classifier:\\t\\t{xgb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Additional Modelling\n",
    "\n",
    "Also includes some additional cleaning, as portrayed below.\n",
    "---\n",
    "---\n",
    "We found that the XGB model worked the best and further gridsearching and finetuning was performed on this model.\n",
    "\n",
    "Cleaning:  Consolidating the possible protest outcomes into broader, more predictable categories was an essential step.  Due to the extremely high baselines of a number of the possible state responses to protests (most protests do NOT result in killings or shootings!), we combined some of the less likely outcomes into single features in order to predict the outcome of the protest better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These responses were folded into broader categories, so they were dropped.\n",
    "new_drops = ['y_arrests', 'y_crowd_dispersal', 'y_beatings', 'y_killings', 'y_shootings']\n",
    "\n",
    "#Adverse reaction includes arrests and/or crowd dispersal\n",
    "df[\"y_adverse_reaction\"] = df[\"y_arrests\"] + df[\"y_crowd_dispersal\"]\n",
    "df[\"y_adverse_reaction\"] = df[\"y_adverse_reaction\"].map(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "#State violence includes any or all of the following:  beatings, killings, or shootings\n",
    "df[\"y_state_violence\"] = df[\"y_beatings\"] + df[\"y_killings\"] + df[\"y_shootings\"]\n",
    "df[\"y_state_violence\"] = df[\"y_state_violence\"].map(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "#Finally, we drop the outdated responses.\n",
    "df.drop(columns=new_drops, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When performing this cleaning, we found a problem with the original data:  some values of demands or responses were \"doubled\" - \n",
    "#an entry for a demand or a response was entered twice in the same row.  \n",
    "#This means in the final dummified responses or demands, not all values are 0 or 1.  They might be a 2.  \n",
    "#This code fixes for that by collapsing any number higher than one into a 1.\n",
    "\n",
    "possible_responses = ['y_accomodation', 'y_ignore', 'y_adverse_reaction', 'y_state_violence']\n",
    "possible_demands = ['demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
    "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
    "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
    "       'demand_social_restrictions']\n",
    "\n",
    "for r in possible_responses:\n",
    "    df[r] = df[r].map(lambda x: 1 if x>0 else 0)\n",
    "    \n",
    "for d in possible_demands:\n",
    "    df[d] = df[d].map(lambda x: 1 if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#North America was also dropped due to how the data was included - there were no values for the USA and only 47 for Canada.  \n",
    "#The rest of the values in North America were for Mexico and other Caribbean nations, which we folded into Central America.\n",
    "\n",
    "df = df[df[\"country\"]!=\"Canada\"]\n",
    "df[\"region\"] = df[\"region\"].map(lambda x: \"Central America\" if x==\"North America\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the remaining text columns into a single text column so CountVectorizer can work on it.\n",
    "df[\"notes\"] = df[\"notes\"] + \" \" + df[\"sources\"] + \" \" + df[\"protesteridentity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the dataframe to have only years in the 2000s so that it's more contemporarily accurate.  We lose 4000 out of 10000 values by doing this.\n",
    "df = df[df[\"year\"]>=2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redefining some values to reflex changes in modelling.\n",
    "region_list = dict(df[\"region\"].value_counts()).keys()\n",
    "\n",
    "country_list = dict(df[\"country\"].value_counts()).keys()\n",
    "\n",
    "all_features = ['year', 'country', 'protesterviolence', 'participants', \n",
    "       'protest_length', 'demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
    "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
    "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
    "       'demand_social_restrictions', 'notes']\n",
    "\n",
    "num_features = ['protesterviolence', 'participants', 'protest_length',\n",
    "       'demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
    "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
    "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
    "       'demand_social_restrictions']\n",
    "\n",
    "#In the final models, we dummified year and country for each model run to try and eke up our accuracy.\n",
    "dummy_features = ['year', 'country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'year', 'region', 'protesterviolence', 'participants',\n",
       "       'protesteridentity', 'sources', 'notes', 'protest_length',\n",
       "       'demand_labor_wage_dispute', 'demand_land_farm_issue',\n",
       "       'demand_police_brutality', 'demand_political_behavior_or_process',\n",
       "       'demand_price_hike_or_tax_policy', 'demand_removal_of_politician',\n",
       "       'demand_social_restrictions', 'y_accomodation', 'y_ignore',\n",
       "       'y_adverse_reaction', 'y_state_violence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell was run many times with gridsearches to try and fine-tune the model.  When the best combination of parameters was found, we removed the gridsearch\n",
    "#and replaced it with the bare pipe.  The best results of xgb were also saved to a dataframe - much smaller than the 196 row frame we had before.\n",
    "#We also had some continuous and un-abateable issues with overfitting.\n",
    "\n",
    "def xgb__protest_by_the_response(df, response):\n",
    "    df = pd.get_dummies(df, columns=[\"year\", \"country\"], drop_first=True)\n",
    "    \n",
    "    #forbiddens correspond to features that do not go into the X vals but are still needed in the df\n",
    "    forbiddens = [\"region\", \"protesteridentity\", \"sources\", \"y_accomodation\", \"y_ignore\", \"y_adverse_reaction\", \"y_state_violence\"]\n",
    "    xgb_features = [i for i in df.columns if i not in forbiddens]\n",
    "    \n",
    "    #tweaking how num_features is declared so that it has everything numeric that is not in forbiddens.\n",
    "    numerics = ['int64', 'float64', 'uint8']\n",
    "    num_features = [i for i in df.select_dtypes(include=numerics).columns if i not in forbiddens]\n",
    "    \n",
    "    X = df[xgb_features]\n",
    "    y = df[response]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    #Getting the numeric and text data calls with our FunctionTransformers\n",
    "    get_numeric_data = FunctionTransformer(lambda df: df[num_features], validate=False)\n",
    "    get_text_data = FunctionTransformer(lambda df: df[\"notes\"], validate=False)\n",
    "    \n",
    "    #declaring the pipeline with best parameters\n",
    "    pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "             ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer(stop_words='english', max_df=0.8, max_features=2000))\n",
    "            ]))\n",
    "         ])),\n",
    "    ('xg', XGBClassifier(max_depth=2, learning_rate=0.05))\n",
    "    ])\n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    baseline = max([df[response].mean(), 1-df[response].mean()])\n",
    "            \n",
    "    reg_response_dict = {\n",
    "        \"model_type\": \"xgb\",\n",
    "        \"region\": df[\"region\"].iloc[0],\n",
    "        \"training_score\": pipe.score(X_train, y_train),\n",
    "        \"testing_score\": pipe.score(X_test, y_test),\n",
    "        \"baseline\": baseline,\n",
    "        \"baseline_response\": (response[2:] if df[response].mean() > 0.5 else f\"no {response[2:]}\"),\n",
    "        \"model_success\": (\"yes\" if pipe.score(X_test, y_test) > (0.05+baseline) else \"no\"), #If the model is running more than 5 percentage points above the baseline in that category, it is noted as being more reliable than if not.\n",
    "#        \"best_params\": gs.best_params_  #This entry is no longer needed since we don't have a gridsearch any more.\n",
    "    }\n",
    "    \n",
    "    return reg_response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make sure everything is still the same the bounding loop functions for the model function are declared or adjusted as needed.\n",
    "def xgb__responses_by_location(loc_df):\n",
    "    return [xgb__protest_by_the_response(loc_df, response) for response in possible_responses]\n",
    "\n",
    "def df_by_region(df, region):\n",
    "    return df[df[\"region\"]==region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As before, we declare an empty results dataframe and append returned dictionaries to it, but this time with much better accuracy due to the reduction in dimensionality.\n",
    "\n",
    "xgb_results = pd.DataFrame(columns=[\"model_type\", \"region\", \"baseline_response\", \"training_score\", \"testing_score\", \"baseline\", \"model_success\"])\n",
    "\n",
    "\n",
    "for region in region_list:\n",
    "    for dct in xgb__responses_by_location(df_by_region(df, region)):\n",
    "        xgb_results = xgb_results.append(dct, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>region</th>\n",
       "      <th>baseline_response</th>\n",
       "      <th>training_score</th>\n",
       "      <th>testing_score</th>\n",
       "      <th>baseline</th>\n",
       "      <th>model_success</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgb</td>\n",
       "      <td>Europe</td>\n",
       "      <td>no accomodation</td>\n",
       "      <td>0.943381</td>\n",
       "      <td>0.953808</td>\n",
       "      <td>0.933500</td>\n",
       "      <td>no</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgb</td>\n",
       "      <td>Europe</td>\n",
       "      <td>ignore</td>\n",
       "      <td>0.853039</td>\n",
       "      <td>0.868914</td>\n",
       "      <td>0.685607</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgb</td>\n",
       "      <td>Europe</td>\n",
       "      <td>no adverse_reaction</td>\n",
       "      <td>0.899251</td>\n",
       "      <td>0.893883</td>\n",
       "      <td>0.727131</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgb</td>\n",
       "      <td>Europe</td>\n",
       "      <td>no state_violence</td>\n",
       "      <td>0.976686</td>\n",
       "      <td>0.982522</td>\n",
       "      <td>0.975960</td>\n",
       "      <td>no</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xgb</td>\n",
       "      <td>Africa</td>\n",
       "      <td>no accomodation</td>\n",
       "      <td>0.895176</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.864672</td>\n",
       "      <td>no</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xgb</td>\n",
       "      <td>Africa</td>\n",
       "      <td>no ignore</td>\n",
       "      <td>0.834425</td>\n",
       "      <td>0.801786</td>\n",
       "      <td>0.590442</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xgb</td>\n",
       "      <td>Africa</td>\n",
       "      <td>no adverse_reaction</td>\n",
       "      <td>0.858845</td>\n",
       "      <td>0.869643</td>\n",
       "      <td>0.521661</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xgb</td>\n",
       "      <td>Africa</td>\n",
       "      <td>no state_violence</td>\n",
       "      <td>0.896367</td>\n",
       "      <td>0.891071</td>\n",
       "      <td>0.810183</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xgb</td>\n",
       "      <td>Asia</td>\n",
       "      <td>no accomodation</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.879017</td>\n",
       "      <td>0.865248</td>\n",
       "      <td>no</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xgb</td>\n",
       "      <td>Asia</td>\n",
       "      <td>ignore</td>\n",
       "      <td>0.796343</td>\n",
       "      <td>0.793951</td>\n",
       "      <td>0.539480</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xgb</td>\n",
       "      <td>Asia</td>\n",
       "      <td>no adverse_reaction</td>\n",
       "      <td>0.819042</td>\n",
       "      <td>0.803403</td>\n",
       "      <td>0.649173</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xgb</td>\n",
       "      <td>Asia</td>\n",
       "      <td>no state_violence</td>\n",
       "      <td>0.915511</td>\n",
       "      <td>0.897921</td>\n",
       "      <td>0.881797</td>\n",
       "      <td>no</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xgb</td>\n",
       "      <td>South America</td>\n",
       "      <td>no accomodation</td>\n",
       "      <td>0.920378</td>\n",
       "      <td>0.899194</td>\n",
       "      <td>0.899899</td>\n",
       "      <td>no</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xgb</td>\n",
       "      <td>South America</td>\n",
       "      <td>ignore</td>\n",
       "      <td>0.832659</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.580384</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xgb</td>\n",
       "      <td>South America</td>\n",
       "      <td>no adverse_reaction</td>\n",
       "      <td>0.882591</td>\n",
       "      <td>0.842742</td>\n",
       "      <td>0.644085</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xgb</td>\n",
       "      <td>South America</td>\n",
       "      <td>no state_violence</td>\n",
       "      <td>0.952767</td>\n",
       "      <td>0.931452</td>\n",
       "      <td>0.929221</td>\n",
       "      <td>no</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>xgb</td>\n",
       "      <td>MENA</td>\n",
       "      <td>no accomodation</td>\n",
       "      <td>0.934993</td>\n",
       "      <td>0.941909</td>\n",
       "      <td>0.913900</td>\n",
       "      <td>no</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>xgb</td>\n",
       "      <td>MENA</td>\n",
       "      <td>no ignore</td>\n",
       "      <td>0.817427</td>\n",
       "      <td>0.804979</td>\n",
       "      <td>0.552905</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>xgb</td>\n",
       "      <td>MENA</td>\n",
       "      <td>no adverse_reaction</td>\n",
       "      <td>0.832642</td>\n",
       "      <td>0.834025</td>\n",
       "      <td>0.604772</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>xgb</td>\n",
       "      <td>MENA</td>\n",
       "      <td>no state_violence</td>\n",
       "      <td>0.874136</td>\n",
       "      <td>0.804979</td>\n",
       "      <td>0.765560</td>\n",
       "      <td>no</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>xgb</td>\n",
       "      <td>Central America</td>\n",
       "      <td>no accomodation</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>no</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>xgb</td>\n",
       "      <td>Central America</td>\n",
       "      <td>ignore</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.636667</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>xgb</td>\n",
       "      <td>Central America</td>\n",
       "      <td>no adverse_reaction</td>\n",
       "      <td>0.931111</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>xgb</td>\n",
       "      <td>Central America</td>\n",
       "      <td>no state_violence</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>no</td>\n",
       "      <td>{'xg__learning_rate': 0.05, 'xg__max_depth': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_type           region    baseline_response  training_score  \\\n",
       "0         xgb           Europe      no accomodation        0.943381   \n",
       "1         xgb           Europe               ignore        0.853039   \n",
       "2         xgb           Europe  no adverse_reaction        0.899251   \n",
       "3         xgb           Europe    no state_violence        0.976686   \n",
       "4         xgb           Africa      no accomodation        0.895176   \n",
       "5         xgb           Africa            no ignore        0.834425   \n",
       "6         xgb           Africa  no adverse_reaction        0.858845   \n",
       "7         xgb           Africa    no state_violence        0.896367   \n",
       "8         xgb             Asia      no accomodation        0.885246   \n",
       "9         xgb             Asia               ignore        0.796343   \n",
       "10        xgb             Asia  no adverse_reaction        0.819042   \n",
       "11        xgb             Asia    no state_violence        0.915511   \n",
       "12        xgb    South America      no accomodation        0.920378   \n",
       "13        xgb    South America               ignore        0.832659   \n",
       "14        xgb    South America  no adverse_reaction        0.882591   \n",
       "15        xgb    South America    no state_violence        0.952767   \n",
       "16        xgb             MENA      no accomodation        0.934993   \n",
       "17        xgb             MENA            no ignore        0.817427   \n",
       "18        xgb             MENA  no adverse_reaction        0.832642   \n",
       "19        xgb             MENA    no state_violence        0.874136   \n",
       "20        xgb  Central America      no accomodation        0.955556   \n",
       "21        xgb  Central America               ignore        0.880000   \n",
       "22        xgb  Central America  no adverse_reaction        0.931111   \n",
       "23        xgb  Central America    no state_violence        0.946667   \n",
       "\n",
       "    testing_score  baseline model_success  \\\n",
       "0        0.953808  0.933500            no   \n",
       "1        0.868914  0.685607           yes   \n",
       "2        0.893883  0.727131           yes   \n",
       "3        0.982522  0.975960            no   \n",
       "4        0.900000  0.864672            no   \n",
       "5        0.801786  0.590442           yes   \n",
       "6        0.869643  0.521661           yes   \n",
       "7        0.891071  0.810183           yes   \n",
       "8        0.879017  0.865248            no   \n",
       "9        0.793951  0.539480           yes   \n",
       "10       0.803403  0.649173           yes   \n",
       "11       0.897921  0.881797            no   \n",
       "12       0.899194  0.899899            no   \n",
       "13       0.822581  0.580384           yes   \n",
       "14       0.842742  0.644085           yes   \n",
       "15       0.931452  0.929221            no   \n",
       "16       0.941909  0.913900            no   \n",
       "17       0.804979  0.552905           yes   \n",
       "18       0.834025  0.604772           yes   \n",
       "19       0.804979  0.765560            no   \n",
       "20       0.920000  0.943333            no   \n",
       "21       0.840000  0.636667           yes   \n",
       "22       0.873333  0.691667           yes   \n",
       "23       0.920000  0.916667            no   \n",
       "\n",
       "                                        best_params  \n",
       "0   {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "1   {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "2   {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "3   {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "4   {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "5   {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "6   {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "7   {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "8   {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "9   {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "10  {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "11  {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "12  {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "13  {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "14  {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "15  {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "16  {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "17  {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "18  {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "19  {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "20  {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "21  {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "22  {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  \n",
       "23  {'xg__learning_rate': 0.05, 'xg__max_depth': 2}  "
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Success Rate above baseline:\t\t\t\t0.11863320206114623\n",
      "XGB Success Rate above baseline (for baselines under 85%):\t0.1961123595634164\n"
     ]
    }
   ],
   "source": [
    "#Some additional information about how the XGB results performed against baseline and overall in this cell and the next.\n",
    "\n",
    "xgb_results[\"success_rate\"] = xgb_results[\"testing_score\"] - xgb_results[\"baseline\"]\n",
    "\n",
    "xgb_total_success = xgb_results[\"success_rate\"].mean()\n",
    "xgb_low_success = xgb_results[xgb_results[\"baseline\"]<0.85][\"success_rate\"].mean()\n",
    "\n",
    "print(f\"XGB Success Rate above baseline:\\t\\t\\t\\t{xgb_total_success}\")\n",
    "print(f\"XGB Success Rate above baseline (for baselines under 85%):\\t{xgb_low_success}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:   0.9631988697246057\n",
      "testing:   0.8502163242241233\n",
      "baseline:   0.7449533102118207\n"
     ]
    }
   ],
   "source": [
    "xgb_df = pd.read_csv(\"./data/xgb_results.csv\")\n",
    "print(\"training:  \", xgb_df[\"training_score\"].mean())\n",
    "print(\"testing:  \", xgb_df[\"testing_score\"].mean())\n",
    "print(\"baseline:  \", xgb_df[\"baseline\"].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
